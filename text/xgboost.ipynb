{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(pos_matrix, neg_matrix, train_prop=0.7, repeats=6):\n",
    "    '''\n",
    "    repeats:训练集中，正例的复制倍数\n",
    "    '''\n",
    "    import numpy as np\n",
    "    #shuffle\n",
    "    np.random.shuffle(pos_matrix)\n",
    "    np.random.shuffle(neg_matrix)\n",
    "    #split data\n",
    "    pos_train_size=int(pos_matrix.shape[0]*train_prop)\n",
    "    neg_train_size=int(neg_matrix.shape[0]*train_prop)\n",
    "\n",
    "    train_pos=pos_matrix[:pos_train_size]\n",
    "    train_neg=neg_matrix[:neg_train_size]\n",
    "    train_pos=np.tile(train_pos,(repeats,1))\n",
    "    test_pos=pos_matrix[pos_train_size:]\n",
    "    test_neg=neg_matrix[neg_train_size:]\n",
    "    #test_pos=np.tile(test_pos,(6,1))\n",
    "\n",
    "    x_train=np.vstack((train_pos,train_neg))\n",
    "    y_train=np.vstack((np.ones((len(train_pos),1)),np.zeros((len(train_neg),1))))\n",
    "    x_test=np.vstack((test_pos,test_neg))\n",
    "    y_test=np.vstack((np.ones((len(test_pos),1)),np.zeros((len(test_neg),1))))\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def get_metrics(pre_y,y):\n",
    "    auc_score = roc_auc_score(y,pre_y)\n",
    "    pre_score = precision_score(y,pre_y)\n",
    "    rec_score=recall_score(y,pre_y)\n",
    "    f_score=f1_score(y,pre_y)\n",
    "\n",
    "    print(\"xgb_auc_score:\",auc_score)\n",
    "    print(\"xgb_pre_score:\",pre_score)\n",
    "    print(\"xgb_rec_score:\",rec_score)\n",
    "    print(\"xgb_f1_score:\",f_score)\n",
    "    return auc_score, pre_score, rec_score, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import precision_score,roc_auc_score,recall_score,f1_score\n",
    "\n",
    "#load data\n",
    "pos_matrix=np.load(\"data/bert/matrix/pos_matrix.npy\")\n",
    "neg_matrix=np.load(\"data/bert/matrix/neg_matrix.npy\")\n",
    "x_train, y_train, x_test, y_test=train_test_split(pos_matrix, neg_matrix, train_prop=0.7)\n",
    "print(\"Data processing completed\")\n",
    "\n",
    "xgbc = XGBClassifier()\n",
    "xgbc.fit(x_train,y_train)\n",
    "print(\"xgboost training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train = xgbc.predict(x_train)\n",
    "get_metrics(pre_train,y_train)\n",
    "print(\"----------\")\n",
    "pre_test = xgbc.predict(x_test)\n",
    "get_metrics(pre_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import precision_score,roc_auc_score,recall_score,f1_score\n",
    "from gensim.models import Word2Vec  \n",
    "\n",
    "#load data\n",
    "pos_matrix=np.zeros((0,256))\n",
    "neg_matrix=np.zeros((0,256))\n",
    "model=Word2Vec.load(\"model/word2vec/word2vec\")\n",
    "print(\"word2vec model loaded.\")\n",
    "with open(\"data/samples/positive.txt\", encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        words=[w for w in line.split() if w in model]\n",
    "        if not words:\n",
    "            continue\n",
    "        pos_matrix=np.vstack((pos_matrix,model.wv[words].mean(0)))\n",
    "print(\"positive matrix completed.\")\n",
    "with open(\"data/samples/negative.txt\", encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        words=[w for w in line.split() if w in model]\n",
    "        if not words:\n",
    "            continue\n",
    "        neg_matrix=np.vstack((neg_matrix,model.wv[words].mean(0)))\n",
    "print(\"negative matrix completed.\")\n",
    "x_train, y_train, x_test, y_test=train_test_split(pos_matrix, neg_matrix, train_prop=0.7,repeats=4)\n",
    "print(\"Data processing completed\")\n",
    "\n",
    "xgbc = XGBClassifier()\n",
    "xgbc.fit(x_train,y_train)\n",
    "print(\"xgboost training completed\")\n",
    "xgbc.save_model(\"model/xgb/xgb.word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train = xgbc.predict(x_train)\n",
    "get_metrics(pre_train,y_train)\n",
    "print(\"----------\")\n",
    "pre_test = xgbc.predict(x_test)\n",
    "get_metrics(pre_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm 效果不如xgboost\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf=LinearSVC()\n",
    "clf.fit(X=x_train,y=y_train)\n",
    "\n",
    "pre_train=clf.predict(x_train)\n",
    "get_metrics(pre_train,y_train)\n",
    "print(\"----------\")\n",
    "pre_test = clf.predict(x_test)\n",
    "get_metrics(pre_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
